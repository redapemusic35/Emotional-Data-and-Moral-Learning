demo()
y <- c(x, 0, x)
assign("x", c(10.4, 5.6, 3.1, 6.4, 21.7))
c(10.4, 5.6, 3.1, 6.4, 21.7) -> x
1/x
y <- c(x, 0, x)
v <- 2*x + y + 1
sum((x-mean(x))^2)/(length(x)-1)
seq(-5, 5, by=.2) -> s3
openssl
install.packages(c("tidyverse", "openssl", "readtext"))
install.packages("httr")
devtools::install_github("tidyverse")
install.packages("devtools")
install.packages("openssl")
install.packages(c("tidyverse", "readtext"))
install.packages("readtext")
install.packages("pdftools")
install.packages("readtext")
install.packages("pdftools")
install.packages("pdftools")
install.packages("pdftools")
install.packages("readtext")
install.packages("tidyverse")
library(quanteda)
murder2_keys <- read.delim("~/VimWiki/subjects/digital-humanities/mallet-txt-files/murder2_keys.txt", header=FALSE)
View(murder2_keys)
textplot_wordcloud(murder2_keys)
corpus(murder2_keys)
library(readtext)
install.packages("readtext")
library(readtext)
data.frame(murder2_keys)
doc.corpus <- corpus(data.frame)
doc.corpus <- corpus(murder2_keys)
doc.corpus <- corpus(dataframe)
dataframe <- readtext(murder2_keys)
dataframe <- readtext("murder2_keys)
docvarnames = c("V3", "V2")
dataframe <- readtext("murder2_keys)
docvars(x, V3)
exit
docid(V2)
docid(V3)
dataframe <- readtext("murder2_keys)
library(quanteda)
library(readtext)
dir.create("tmp")
download.file(url = "http://www.gutenberg.org/files/1342/1342-0.txt",)
dataframe <- readtext("~/VimWiki/subjects/digital-humanities/mallet-txt-files/murder2_keys.txt")
doc.corpus <- corpus(dataframe)
summary(doc.corpus)
doc.tokens <- tokens(doc.corpus)
doc.tokens <- tokens(doc.tokens)
doc.dfm <- dfm(doc.corpus, remove_numbers = TRUE)
textplot_wordcloud()
textplot_wordcloud(doc.dfm)
textplot_wordcloud(doc.dfm, x, min_size = 5, max_size = 100, min_count = 5, color = blues9)
textplot_wordcloud(  x,
min_size = 0.5,
max_size = 4,
min_count = 3,
max_words = 500,
color = "darkblue",
font = NULL,
adjust = 0,
rotation = 0.1,
random_order = FALSE,
random_color = FALSE,
ordered_color = FALSE,
labelcolor = "gray20",
labelsize = 1.5,
labeloffset = 0,
fixed_aspect = TRUE,
...,
comparison = FALSE)
textplot_wordcloud(doc.dfm)
textplot_wordcloud(doc.dfm, comparison = TRUE, max_words = 300, color = c("blue", "red"))
textplot_wordcloud(doc.dfm, comparison = TRUE, max_words = 5, color = c("blue", "red"))
doc.dfm <- dfm(doc.corpus, remove_numbers = FALSE)
textplot_wordcloud(doc.dfm, comparison = TRUE, max_words = 5, color = c("blue", "red"))
inaugDFM <- dfm(data_co)
inaugDFM <- dfm(data_corpus_inaugural[0:10], remove = stopwords("english"), removePunct = TRUE)
textplot_wordcloud(dfm_trim(inaugDFM, min_count = 10, verbose = FALSE))
dataframe <- readtext("/home/redapemusic35/VimWiki/subjects/digital-humanities/projects/lyrics.csv")
doc.corpus <- corpus(dataframe)
doc.corpus <- corpus(dataframe)
dataframe <- readtext("/home/redapemusic35/VimWiki/subjects/digital-humanities/projects/country.txt")
doc.corpus <- corpus(dataframe)
summary(doc.corpus)
inaugDFM <- dfm(data_char_wordlists[0:10], remove = stopwords('english'), removePunct = TRUE)
inaugDFM <- dfm(data_corpus_inaugural[0:10], remove = stopwords('english'), removePunct = TRUE)
textplot_wordcloud(dfm_trim(inaugDFM, min_count = 10, verbose = FALSE))
library(zoom)
install.packages("zoom")
library(zoom)
inaugDFM <- dfm(data_corpus_inaugural[0:10], remove = stopwords('english'), removePunct = TRUE)
textplot_wordcloud(dfm_trim(inaugDFM, min_count = 10, verbose = FALSE))
# Chunk 1
# Chunk 1
more.hearts <- read.table("~/VimWiki/subjects/digital-humanities/projects/more-hearts.txt", header=TRUE, quote="\"")
View(more.hearts)
more.hearts <- read.csv("~/VimWiki/subjects/digital-humanities/projects/more-hearts.csv")
View(more.hearts)
more.hearts <- read.csv("~/VimWiki/subjects/digital-humanities/projects/more-hearts.csv")
View(more.hearts)
textplot_wordcloud(dfm_trim(inaugDFM, min_count = 10, verbose = FALSE))
textplot_wordcloud(dfm_trim(inaugDFM, min_termfreq = 10, verbose = FALSE))
library(zoom)
textplot_wordcloud(dfm_trim(inaugDFM, min_termfreq = 10, verbose = FALSE))
inaugFeatures <- topfeatures(inaugDFM, 100)
topDF <- data.frame()
topDF <- data.frame(list(term = names(inaugFeatures), frequency = unname(inaugFeatures)))
topDF$term <- with(topDF, reorder(term, -frequency))
ggplot(topDF) + geom_point(aes(x=term, y=frequency)) +
theme(axis.text.x=element_text(angle=90, hjust=1))
library(ggplot2)
topDF <- data.frame(list(term = names(inaugFeatures), frequency = unname(inaugFeatures)))
topDF$term <- with(topDF, reorder(term, -frequency))
topDF$term <- with(topDF, reorder(term, -frequency))
ggplot(topDF) + geom_point(aes(x=term, y=frequency)) +
theme(axis.text.x=element_text(angle=90, hjust=1))
y
library(sotu)
library(ggplot2)
library(cleanNLP)
cnlp_init_udpipe(model_name="english")
input <- sotu_meta
input$text <- sotu_text
anno <- cnlp_annotate(input)
library(sotu)
library(ggplot2)
library(cleanNLP)
cnlp_init_cnlp_init_stringi(locale="en")
library(sotu)
library(ggplot2)
library(cleanNLP)
cnlp_init_stringi(locale="en")
input <- sotu_meta
input$text <- sotu_text
anno <- cnlp_annotate(input)
anno
library(sotu)
library(ggplot2)
library(cleanNLP)
cnlp_init_stringi(locale="en")
input <- sotu_meta
input$text <- sotu_text
anno <- cnlp_annotate(input)
anno
anno$token %>%
group_by(doc_id, sid) %>%
summarize(sent_len = n()) %>%
quantile(sent_len, seq(0,1,0.1))
library(sotu)
library(ggplot2)
library(cleanNLP)
cnlp_init_stringi(locale="en")
input <- sotu_meta
input$text <- sotu_text
anno <- cnlp_annotate(input)
anno
anno$token %>%
group_by(George Washington, sid) %>%
library(sotu)
library(ggplot2)
library(cleanNLP)
cnlp_init_stringi(locale="en")
input <- sotu_meta
input$text <- sotu_text
anno <- cnlp_annotate(input)
anno
anno$token %>%
filter(upos == "NOUN") %>%
group_by(lemma) %>%
summarize(count = n()) %>%
top_n(n = 42, count) %>%
arrange(desc(count)) %>%
use_series(lemma)
library(sotu)
library(ggplot2)
library(cleanNLP)
cnlp_init_stringi(locale="en")
input <- sotu_meta
input$text <- sotu_text
anno <- cnlp_annotate(input)
anno
anno$token %>%
group_by(lemma) %>%
summarize(count = n()) %>%
top_n(n = 42, count) %>%
arrange(desc(count)) %>%
use_series(lemma)
library(sotu)
library(ggplot2)
library(cleanNLP)
cnlp_init_stringi(locale="en")
input <- sotu_meta
input$text <- sotu_text
anno <- cnlp_annotate(input)
anno
anno$token %>%
group_by(doc_id) %>%
summarize(n = n()) %>%
left_join(anno$document, by="doc_id") %>%
ggplot(aes(year, n)) +
geom_line(color = grey(0.8)) +
geom_point(aes(color = sotu_type)) +
geom_smooth(method="loess", formula = y ~ x) +
theme_minimal()
library(sotu)
library(ggplot2)
library(cleanNLP)
cnlp_init_cleannlp(locale="en")
library(sotu)
library(ggplot2)
library(cleanNLP)
cnlp_init_corenlp(lang="en")
library(sotu)
library(ggplot2)
library(cleanNLP)
cnlp_download_spacy(model_name="en")
cnlp_download_corenlp(lang="en")
help("cleanNLP")
cnlp_init_corenlp()
cnlp_init_corenlp(lang = NULL, models_dir = NULL, config = NULL)
library(sotu)
library(ggplot2)
library(cleanNLP)
core <- cnlp_init_corenlp(lang="en")
library(sotu)
library(ggplot2)
library(cleanNLP)
initCoreNLP(lang="en")
library(sotu)
library(ggplot2)
library(cleanNLP)
initCoreNLP()
library(sotu)
library(ggplot2)
library(cleanNLP)
initcleanNLP()
library(sotu)
library(ggplot2)
library(cleanNLP)
cnlp_init_corenlp()
devtools::session_info()
reticulate::py_discover_config(required_module="cleannlp")
reticulate::py_config()
reticulate::import("cleannlp") # this should give an error, but it's helpful to check
library(cleanNLP)
import(cleanNLP)
library(cleanNLP)
use_python("/home/redapemusic35/.local/share/r-miniconda/envs/r-reticulate/bin/python")
library(cleanNLP)
cnlp_init_corenlp()
library(cleanNLP)
cnlp_init_spacy("en")
library(stanfordnlp)
library(stanfordnlp)
library(stanfordnlp)
library(cleanNLP)
cnlp_init_spacy()
library(cleanNLP)
cnlp_init_spacy("en")
library(cleanNLP)
use_python("/home/redapemusic35/.local/share/r-miniconda/envs/r-reticulate/bin/python")
library(cleanNLP)
cnlp_init_corenlp()
use_condaenv( "r-reticulate")
conda_install(envname = "r-reticulate", packages="coreNLP")
conda_install(envname = "r-reticulate", packages="cleanNLP")
use_condaenv("r-miniconda")
install.packages("reticulate")
install.packages("reticulate")
library(cleanNLP)
cnlp_init_spacy()
cnlp_download_corenlp()
library(cleanNLP)
init_coreNLP(speed = 2L)
library(cleanNLP)
cnlp_init_corenlp(speed = 2L)
library(cleanNLP)
cnlp_init_corenlp()
library(cleanNLP)
cnlp_init_udpipe()
text <- c("The regular early morning yell of horror was the sound of",
"Arthur Dent waking up and suddenly remembering where he",
"was. It wasn't just that the cave was cold, it wasn't just",
"that it was damp and smelly. It was the fact that the cave",
"was in the middle of Islington and there wasn't a bus due",
"for two million years.")
text <- paste(text, collapse = " ")
obj <- annotate(text, as_strings = TRUE, backend = "coreNLP")
library(cleanNLP)
cnlp_init_udpipe()
text <- c("The regular early morning yell of horror was the sound of",
"Arthur Dent waking up and suddenly remembering where he",
"was. It wasn't just that the cave was cold, it wasn't just",
"that it was damp and smelly. It was the fact that the cave",
"was in the middle of Islington and there wasn't a bus due",
"for two million years.")
text <- paste(text, collapse = " ")
obj <- cnlp_annotate(text, as_strings = TRUE, backend = "coreNLP")
library(cleanNLP)
cnlp_init_udpipe()
text <- c("The regular early morning yell of horror was the sound of",
"Arthur Dent waking up and suddenly remembering where he",
"was. It wasn't just that the cave was cold, it wasn't just",
"that it was damp and smelly. It was the fact that the cave",
"was in the middle of Islington and there wasn't a bus due",
"for two million years.")
text <- paste(text, collapse = " ")
obj <- cnlp_annotate(text, backend = "coreNLP")
library(cleanNLP)
cnlp_init_corenlp()
library(cleanNLP)
cnlp_init_corenlp()
source('~/.bogofilter/wordlist.db', encoding = 'UTF-8')
library(cleanNLP)
cnlp_init_corenlp()
library(cleanNLP)
cnlp_init_udpipe()
input <- sotu_meta
library(cleanNLP)
library(sotu)
cnlp_init_udpipe()
input <- sotu_meta
input$text <- sotu_text
anno <- cnlp_annotate(input)
library(cleanNLP)
library(sotu)
cnlp_init_spacy(model_name="en")
library(cleanNLP)
cnlp_init_corenlp("~/stanfordnlp_resources/")
library(cleanNLP)
cnlp_init_corenlp()
library(cleanNLP)
cnlp_init_corenlp()
library(cleanNLP)
cnlp_init_corenlp()
cnlp_init_corenlp()
import(cleannlp)
import(cleannlp)
library(cleannlp)
library(cleanNLP)
cnlp_init_corenlp(lang = "en")
blogdown:::serve_site()
blogdown:::serve_site()
quit()
